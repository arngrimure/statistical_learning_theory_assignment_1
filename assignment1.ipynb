{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999, 1)\n",
      "(2999, 784)\n",
      "(999, 784)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "data_test_small = pd.read_csv('./MNIST_test_small.csv')\n",
    "data_train_small = pd.read_csv('./MNIST_train_small.csv')\n",
    "\n",
    "X_train = np.matrix(data_train_small)\n",
    "y_temp = X_train[:, 0]\n",
    "print(y_temp.shape)\n",
    "y_train = []\n",
    "for i in range(len(y_temp)):\n",
    "    y_train.append(y_temp[i].item(0))\n",
    "y_train = np.asarray(y_train)\n",
    "X_train = np.delete(X_train, 0, 1)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = np.matrix(data_test_small)\n",
    "y_temp = X_test[:, 0]\n",
    "y_test = []\n",
    "for i in range(len(y_temp)):\n",
    "    y_test.append(y_temp[i].item(0))\n",
    "y_test = np.asarray(y_test)\n",
    "X_test = np.delete(X_test, 0, 1)\n",
    "\n",
    "\n",
    "test = []\n",
    "for i in range(len(X_train)):\n",
    "    temp = np.transpose(X_train[i])\n",
    "    img = []\n",
    "    for j in range(len(temp)):\n",
    "        img.append(temp[j].item(0))\n",
    "    img = np.asarray(img)\n",
    "    test.append(img)\n",
    "test = np.asarray(test)\n",
    "X_train = test\n",
    "\n",
    "\n",
    "test2 = []\n",
    "for i in range(len(X_test)):\n",
    "    temp = np.transpose(X_test[i])\n",
    "    img = []\n",
    "    for j in range(len(temp)):\n",
    "        img.append(temp[j].item(0))\n",
    "    img = np.asarray(img)\n",
    "    test2.append(img)\n",
    "test2 = np.asarray(test2)\n",
    "X_test = test2\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(placement, train_test=True):\n",
    "    if train_test:\n",
    "        # The rest of columns are pixels\n",
    "        pixels = X_train[placement]\n",
    "\n",
    "        # Make those columns into a array of 8-bits pixels\n",
    "        # This array will be of 1D with length 784\n",
    "        # The pixel intensity values are integers from 0 to 255\n",
    "        pixels = np.array(pixels, dtype='uint8')\n",
    "\n",
    "        # Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "        pixels = pixels.reshape((28, 28))\n",
    "\n",
    "        # Plot\n",
    "        plt.title('Diget nr. {placement}. Label is {label}'.format(label=y_train[placement], placement=placement))\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        pixels = X_test[placement]\n",
    "        pixels = np.array(pixels, dtype='uint8')\n",
    "        pixels = pixels.reshape((28, 28))\n",
    "\n",
    "        plt.title('Diget nr. {placement}. Label is {label}'.format(label=y_test[placement], placement=placement))\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "plot_digit(0, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(i_train, X_pred):\n",
    "    dist = np.linalg.norm(i_train-X_pred)\n",
    "    return dist\n",
    "\n",
    "def predict(X_pred, k):\n",
    "    dists = []\n",
    "    for i in X_train:\n",
    "        dists.append(get_dist(i, X_pred))\n",
    "    \n",
    "    idx = np.argpartition(dists, k)\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "        \n",
    "    #plot_digit(0, False)\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    return result\n",
    "\n",
    "def KNN(X_data, y_data, k):\n",
    "    num_errors = 0\n",
    "    for i in range(len(X_data)):\n",
    "        pred = predict(X_data[i], k)\n",
    "        if pred != y_data[i]:\n",
    "            num_errors += 1\n",
    "        if i % 20 == 0 and i != 0:\n",
    "            print(\"Iteration:\", i, \"error:\", (num_errors/(i+1))*100,\"%\")\n",
    "        \n",
    "    error = num_errors/len(X_data)\n",
    "    print('For k={k_value} the error is: {error}%'.format(k_value=k, error=error*100))\n",
    "            \n",
    "KNN(X_train, y_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(i_train, X_pred):\n",
    "    dist = np.linalg.norm(i_train-X_pred)\n",
    "    return dist\n",
    "\n",
    "def get_dist_vector(X_pred, k):\n",
    "    dists = []\n",
    "    for i in X_train:\n",
    "        dists.append(get_dist(i, X_pred))\n",
    "        \n",
    "    idx = np.argpartition(dists, k)\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "        \n",
    "    #plot_digit(0, False)\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    dists = np.asarray(dists)\n",
    "    return result, dists\n",
    "\n",
    "def KNN(X_data, y_data, k):\n",
    "    num_errors = 0\n",
    "    \n",
    "    distance_mat = []\n",
    "    \n",
    "    for i in range(len(X_data)):\n",
    "    #for i in range(40):\n",
    "\n",
    "        pred, dist = get_dist_vector(X_data[i], k)\n",
    "        distance_mat.append(dist)\n",
    "        if pred != y_data[i]:\n",
    "            num_errors += 1\n",
    "        if i % 100 == 0 and i != 0:\n",
    "            print(\"Iteration:\",i,\"/\",len(X_data),\"=====\", \"error:\", (num_errors/(i+1))*100,\"%\")\n",
    "        \n",
    "    error = num_errors/len(X_data)\n",
    "    print('For k={k_value} the error is: {error}%'.format(k_value=k, error=error*100))\n",
    "    \n",
    "    distance_mat = np.asarray(distance_mat)\n",
    "    print(distance_mat.shape)\n",
    "    #distance_mat.sort(axis=1)\n",
    "    indx = distance_mat.argsort(axis=1)\n",
    "    print(indx.shape)\n",
    "\n",
    "    return distance_mat, indx\n",
    "\n",
    "\n",
    "k=20\n",
    "distance_matrix_test, indx_mat_test = KNN(X_test, y_test, k)\n",
    "distance_matrix_train, indx_mat_train = KNN(X_train, y_train, k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(k, idx):\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_error(dist_mat, indx, y_data, k):\n",
    "    error_vec = []\n",
    "    for j in range(1, k+1):\n",
    "        err = 0\n",
    "        for i in range(len(dist_mat)):\n",
    "            prediction = get_prediction(j, indx[i])\n",
    "            label = y_data[i]\n",
    "            #print(prediction, label)\n",
    "            if prediction != label:\n",
    "                err += 1\n",
    "        error_vec.append(round((err/len(y_data))*100,2))\n",
    "    return error_vec\n",
    "    #print(error_vec)\n",
    "\n",
    "test_errors = get_error(distance_matrix_test, indx_mat_test, y_test, 20)\n",
    "train_errors = get_error(distance_matrix_train, indx_mat_train, y_train, 20)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linegraph(error_vec, name=\"Errorplot\"):\n",
    "    k = range(1,len(error_vec) + 1)\n",
    "    plt.plot(k, error_vec)\n",
    "    plt.xticks(k)\n",
    "    #plt.axis([1, len(error_vec), 0, 10])\n",
    "    plt.ylabel('Error percentage')\n",
    "    plt.xlabel('k')\n",
    "    plt.title('{e} showing errors with {k} k'.format(k=len(error_vec), e = name))\n",
    "    plt.show()\n",
    "    plt.savefig('{name}.png'.format(name=name))\n",
    "\n",
    "plot_linegraph(test_errors, \"Testing graph\")\n",
    "plot_linegraph(train_errors, \"Training graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_minkowski(i_train, X_pred, p):\n",
    "    dist = (sum((abs(i_train-X_pred))**p))**(1/p) \n",
    "    return dist\n",
    "\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "\n",
    "def get_dist(i_train, X_pred):\n",
    "    dist = np.linalg.norm(i_train-X_pred)\n",
    "    return dist\n",
    "\n",
    "def get_prediction(k, idx):\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_error(dist_mat, indx, y_data, k):\n",
    "    error_vec = []\n",
    "    for j in range(1, k+1):\n",
    "        err = 0\n",
    "        for i in range(len(dist_mat)):\n",
    "            temp = np.delete(indx[i], 0)\n",
    "            prediction = get_prediction(j, temp)\n",
    "            label = y_data[i]\n",
    "            if prediction != label:\n",
    "                err += 1\n",
    "        error_vec.append(round((err/len(y_data))*100,2))\n",
    "    print(error_vec)\n",
    "    return error_vec\n",
    "\n",
    "#test_errors = get_error(distance_matrix_test, indx_mat_test, y_test, 20)\n",
    "\n",
    "train_errors_cross = get_error(distance_matrix_train, indx_mat_train, y_train, 20)\n",
    "\n",
    "plot_linegraph(train_errors_cross, \"Testing graph, cross validation\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap1(a):\n",
    "    plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "    heatmap = plt.pcolor(a)\n",
    "    plt.colorbar(heatmap)\n",
    "    plt.show()\n",
    "    \n",
    "### Helper plotting function. Do not change.\n",
    "import seaborn as sns\n",
    "def plot_heatmap(columns, rows, scores):\n",
    "    \"\"\" Simple heatmap.\n",
    "    Keyword arguments:\n",
    "    columns -- list of options in the columns\n",
    "    rows -- list of options in the rows\n",
    "    scores -- numpy array of scores\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(scores, index=rows, columns=columns)\n",
    "    sns.heatmap(df, cmap='RdYlGn_r', linewidths=0.5, annot=True, fmt=\".3f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is: 1 ===== Iteration: 100 / 2999 ===== error: 14.85148514851485 % Time: 5.131697177886963 sec\n",
      "Estimated time lefti is: 2303.3109613227844 sec\n",
      "p is: 1 ===== Iteration: 200 / 2999 ===== error: 12.935323383084576 % Time: 4.9457550048828125 sec\n",
      "Estimated time lefti is: 2214.9069213867188 sec\n",
      "p is: 1 ===== Iteration: 300 / 2999 ===== error: 12.624584717607974 % Time: 4.929967641830444 sec\n",
      "Estimated time lefti is: 2202.9067410755156 sec\n",
      "p is: 1 ===== Iteration: 400 / 2999 ===== error: 13.216957605985039 % Time: 4.921540975570679 sec\n",
      "Estimated time lefti is: 2194.2198285484315 sec\n",
      "p is: 1 ===== Iteration: 500 / 2999 ===== error: 12.17564870259481 % Time: 4.935826778411865 sec\n",
      "Estimated time lefti is: 2195.653184108734 sec\n",
      "p is: 1 ===== Iteration: 600 / 2999 ===== error: 13.14475873544093 % Time: 4.948030948638916 sec\n",
      "Estimated time lefti is: 2196.1340562438963 sec\n",
      "p is: 1 ===== Iteration: 700 / 2999 ===== error: 11.697574893009985 % Time: 4.925270080566406 sec\n",
      "Estimated time lefti is: 2181.106602478027 sec\n",
      "p is: 1 ===== Iteration: 800 / 2999 ===== error: 11.235955056179774 % Time: 4.934156894683838 sec\n",
      "Estimated time lefti is: 2180.1078823471066 sec\n",
      "p is: 1 ===== Iteration: 900 / 2999 ===== error: 10.876803551609324 % Time: 4.932770252227783 sec\n",
      "Estimated time lefti is: 2174.562437992096 sec\n",
      "p is: 1 ===== Iteration: 1000 / 2999 ===== error: 10.589410589410589 % Time: 4.912281036376953 sec\n",
      "Estimated time lefti is: 2160.617691040039 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1feb2274112e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#p_distance_matrix_test, p_indx_mat_test = KNN_Pvalue(X_test, y_test, k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mp_distance_matrix_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_indx_mat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN_Pvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;31m#print(X_train.dtype)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1feb2274112e>\u001b[0m in \u001b[0;36mKNN_Pvalue\u001b[0;34m(X_data, y_data, k)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m#for i in range(40):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dist_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mdistance_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1feb2274112e>\u001b[0m in \u001b[0;36mget_dist_vector\u001b[0;34m(X_pred, k, p)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#dists.append(get_dist_minkowski(i, X_pred, p))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminkowski\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mminkowski\u001b[0;34m(u, v, p, w)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \"\"\"\n\u001b[1;32m    508\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p must be at least 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0;31m# XXX Is order='c' really necessary?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#c\n",
    "from scipy.spatial import distance\n",
    "import time \n",
    "\n",
    "from math import *\n",
    "from decimal import Decimal \n",
    "\n",
    "def get_dist(i_train, X_pred):\n",
    "    dist = np.linalg.norm(i_train-X_pred)\n",
    "    return dist\n",
    "\n",
    "def p_root(value, root): \n",
    "      \n",
    "    root_value = 1 / float(root) \n",
    "    return round (Decimal(value) **\n",
    "             Decimal(root_value), 3) \n",
    "  \n",
    "def minkowski_distance(x, y, p_value): \n",
    "      \n",
    "    # pass the p_root function to calculate \n",
    "    # all the value of vector parallely  \n",
    "    return (p_root(sum(pow(abs(a-b), p_value) \n",
    "            for a, b in zip(x, y)), p_value)) \n",
    "\n",
    "\n",
    "def get_dist_minkowski(x, y, p):\n",
    "    print(np.abs(x - y) ** p)\n",
    "    dist = np.sum(np.abs(x - y) ** p) ** (1 / p)\n",
    "    #dist = (sum((abs(i_train-X_pred))**p))**(1/p) \n",
    "    return dist\n",
    "\n",
    "def get_dist_vector(X_pred, k, p):\n",
    "    dists = []\n",
    "    for i in X_train:\n",
    "        #dists.append(get_dist_minkowski(i, X_pred, p))\n",
    "        dists.append(distance.minkowski(i, X_pred, p))\n",
    "\n",
    "    idx = np.argpartition(dists, k)\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "        \n",
    "    #plot_digit(0, False)\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    dists = np.asarray(dists)\n",
    "    return result, dists\n",
    "\n",
    "def KNN_Pvalue(X_data, y_data, k):\n",
    "    p_range = 15\n",
    "    chunks = 100\n",
    "    start = time.time()\n",
    "    interval = time.time()\n",
    "    p_distance_matrix = []\n",
    "    p_index_matrix = []\n",
    "    for p in range(1, p_range + 1):\n",
    "        num_errors = 0\n",
    "\n",
    "        distance_mat = []\n",
    "\n",
    "        for i in range(len(X_data)):\n",
    "        #for i in range(40):\n",
    "            pred, dist = get_dist_vector(X_data[i], k, p)\n",
    "            distance_mat.append(dist)\n",
    "            if pred != y_data[i]:\n",
    "                num_errors += 1\n",
    "            if i % chunks == 0 and i != 0:\n",
    "                duration = time.time() - interval\n",
    "                interval = time.time()\n",
    "                estimation = ((((p_range)*len(X_data)) - (p*(i+1)))/chunks) * duration\n",
    "                print(\"p is:\", p, \"===== Iteration:\",i,\"/\",len(X_data),\"=====\", \"error:\", (num_errors/(i+1))*100,\"%\",\"Time:\", duration, \"sec\")\n",
    "                print(\"Estimated time lefti is:\", estimation, \"sec\")\n",
    "        error = num_errors/len(X_data)\n",
    "        print('For k={k_value} the error is: {error}%'.format(k_value=k, error=error*100))\n",
    "\n",
    "        distance_mat = np.asarray(distance_mat)\n",
    "        #distance_mat.sort(axis=1)\n",
    "        indx = distance_mat.argsort(axis=1)\n",
    "        p_distance_matrix.append(distance_mat)\n",
    "        p_index_matrix.append(indx)\n",
    "    p_distance_matrix = np.asarray(p_distance_matrix)\n",
    "    p_index_matrix = np.asarray(p_index_matrix)\n",
    "    print(\"Final time:\", time.time() - start)\n",
    "    return p_distance_matrix, p_index_matrix\n",
    "\n",
    "'''Generate 15 distance matrixes with different p values inside one 3d matrix'''\n",
    "#p_distance_matrix_test, p_indx_mat_test = KNN_Pvalue(X_test, y_test, k)\n",
    "k = 21\n",
    "p_distance_matrix_train, p_indx_mat_train = KNN_Pvalue(X_train, y_train, k)\n",
    "#print(X_train.dtype)\n",
    "\n",
    "X_train=X_train.astype(np.int_)\n",
    "\n",
    "print(X_train.dtype)\n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.minkowski.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Generate a 2d error matrix depending on k and p values'''\n",
    "def get_prediction(k, idx):\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_error(dist_mat, indx, y_data, k, p):\n",
    "    p_error_vec = []\n",
    "    for p in range(1,p+1):\n",
    "        error_vec = []\n",
    "        for j in range(1, k+1):\n",
    "            err = 0\n",
    "            for i in range(len(dist_mat[p-1])):\n",
    "                #print(\"ASDFASDFASDF\",len(dist_mat[p-1]), y_data.shape)\n",
    "                label = y_data[i]\n",
    "                temp = np.delete(indx[p-1][i], 0)\n",
    "                prediction = get_prediction(j, temp)\n",
    "                if prediction != label:\n",
    "                    err += 1\n",
    "            #print(\"err\", err)\n",
    "            error_vec.append(round((err/len(y_data))*100,2))\n",
    "        error_vec = np.asarray(error_vec)\n",
    "        p_error_vec.append(error_vec)\n",
    "    p_error_vec = np.asarray(p_error_vec)\n",
    "    print(p_error_vec)\n",
    "    return p_error_vec\n",
    "\n",
    "#test_errors = get_error(distance_matrix_test, indx_mat_test, y_test, 20)\n",
    "p=7 \n",
    "k=20\n",
    "rows = list(range(1, p + 1))\n",
    "columns = list(range(1, k + 1))\n",
    "p_train_errors_cross = get_error(p_distance_matrix_train, p_indx_mat_train, y_train, k, p)\n",
    "plot_heatmap(columns, rows, p_train_errors_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "distanceMat = TemporaryFile()\n",
    "indexMat = TemporaryFile()\n",
    "\n",
    "x = p_distance_matrix_train\n",
    "y = p_indx_mat_train\n",
    "\n",
    "np.save(\"distanceMat\", x)\n",
    "np.save(\"indexMat\", y)\n",
    "\n",
    "#_ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
    "#p_distance_matrix_train = np.load(\"distanceMat\")\n",
    "#p_indx_mat_train = np.load(\"indexMat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a) Write down your implementation of k-NN neighbors (using as training data\n",
    "MNIST train small.csv) and report on its accuracy to predict the labels\n",
    "in both the training and test sets (respectively MNIST train small.csv and\n",
    "MNIST test small.csv). For this question use the simple Euclidean distance. Make\n",
    "a table of results for k 2 f1; : : : ; 20g, plot your the empirical training and test loss\n",
    "as a function of k, and comment on your results. Explain how ties are broken in\n",
    "Equation 1.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "b) Obviously the choice of the number of neighbors k is crucial to obtain good performance.\n",
    "This choice must be made WITHOUT LOOKING at the test dataset.\n",
    "Although one can use rules-of-thumb, a possibility is to use cross-validation. Leave-\n",
    "One-Out Cross-Validation (LOOCV) is extremely simple in our context. Implement\n",
    "LOOCV to estimate the risk of the k-NN rule for k 2 f1; : : : ; 20g. Report these\n",
    "LOOCV risk estimates4 on a table and plot them as well the empirical loss on the test\n",
    "dataset (that you obtained in (a)). Given your results, what would be a good choice\n",
    "for k? Comment on your results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "c) Obviously, the choice of distance metric also plays an important role. Consider a\n",
    "simple generalization of the Euclidean distance, namely `p distances (also known as\n",
    "Minkowski distances). For x; y 2 Rl de\f",
    "ne\n",
    "dp(x; y) =\n",
    " \n",
    "Xl\n",
    "i=1\n",
    "jxi 􀀀 yijp\n",
    "!1=p\n",
    ";\n",
    "where p \u0015 1. Use leave-one-out cross validation to simultaneously choose a good value\n",
    "for k 2 f1; : : : ; 20g and p 2 [1; 15].\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "d) (this question is more open) Building up on your work for the previous questions\n",
    "suggest a di\u000b",
    "erent distance metric or some pre-processing of the data that you consider\n",
    "appropriate to improve the performance of the k-NN method. Note that, any choices\n",
    "you make should be done solely based on the training data (that is, do not clairvoyantly\n",
    "optimize the performance of your method on the test data). Clearly justify ALL the\n",
    "choices made and describe the exact steps you took. Someone reading your report\n",
    "should be able to replicate your results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now that you implemented and tested your methodologies in a smaller scale, let us see\n",
    "how these methods scale to the full datasets. For the remaining questions you will use the\n",
    "full MNIST training and test sets.\n",
    "\n",
    "e) Make use of either the Euclidean distance or dp with your choice of p in part (c)\n",
    "(use only one or the other). Determine a good value for k using leave-one-out cross\n",
    "validation when considering the full training set (60000 examples). Was your implementation\n",
    "able to cope with this large amount of data? Did you have to modify it\n",
    "in any way? If so, explain what you did. What is the risk estimate you obtain via\n",
    "cross-validation?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "f) (it is only possible to answer this question after I provide you the \f",
    "le\n",
    "MNIST test.csv) Using the choice of k in part (e) compute the loss of your method\n",
    "on the test set provided. How does this compare with the cross-validation estimate\n",
    "you computed in (e)? Would you choose a di\u000b",
    "erent value for k had you been allowed\n",
    "to look at the test dataset earlier?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "g) Bonus question: each training example is currently a high-dimensional vector. A\n",
    "very successful idea in machine learning is that of dimensionality reduction. This is\n",
    "typically done in an unsupervised way - feature vectors are transformed so that most\n",
    "information is preserved, while signi\f",
    "cantly lowering their dimension. A possibility in\n",
    "our setting is to use Principal Component Analysis (PCA) to map each digit image\n",
    "to a lower dimensional vector. There is an enormous computational advantage (as\n",
    "computing distances will be easier) but there might be also an advantage in terms\n",
    "of statistical generalization. Use this idea in our setting, and choose a good number\n",
    "of principal components to keep in order to have good accuracy (again, this choice\n",
    "should be solely based on the training data). Document clearly all the steps of your\n",
    "procedure. In this question you are allowed to use an existing implementation of PCA\n",
    "or related methods.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n = 10\n",
    "X_train_PCA = []\n",
    "for i in X_train:\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(i)\n",
    "    X_train_PCA.append(pca.singular_values_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
