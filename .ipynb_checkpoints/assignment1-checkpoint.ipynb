{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "data_test_small = pd.read_csv('./MNIST_test_small.csv')\n",
    "data_train_small = pd.read_csv('./MNIST_train_small.csv')\n",
    "\n",
    "X_train = np.matrix(data_train_small)\n",
    "y_temp = X_train[:, 0]\n",
    "y_train = []\n",
    "for i in range(len(y_temp)):\n",
    "    y_train.append(y_temp[i].item(0))\n",
    "y_train = np.asarray(y_train)\n",
    "X_train = np.delete(X_train, 0, 1)\n",
    "\n",
    "X_test = np.matrix(data_test_small)\n",
    "y_temp = X_test[:, 0]\n",
    "y_test = []\n",
    "for i in range(len(y_temp)):\n",
    "    y_test.append(y_temp[i].item(0))\n",
    "y_test = np.asarray(y_test)\n",
    "X_test = np.delete(X_test, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(placement, train_test=True):\n",
    "    if train_test:\n",
    "        # The rest of columns are pixels\n",
    "        pixels = X_train[placement]\n",
    "\n",
    "        # Make those columns into a array of 8-bits pixels\n",
    "        # This array will be of 1D with length 784\n",
    "        # The pixel intensity values are integers from 0 to 255\n",
    "        pixels = np.array(pixels, dtype='uint8')\n",
    "\n",
    "        # Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "        pixels = pixels.reshape((28, 28))\n",
    "\n",
    "        # Plot\n",
    "        plt.title('Diget nr. {placement}. Label is {label}'.format(label=y_train[placement], placement=placement))\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        pixels = X_test[placement]\n",
    "        pixels = np.array(pixels, dtype='uint8')\n",
    "        pixels = pixels.reshape((28, 28))\n",
    "\n",
    "        plt.title('Diget nr. {placement}. Label is {label}'.format(label=y_test[placement], placement=placement))\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "plot_digit(0, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(i_train, X_pred):\n",
    "    dist = np.linalg.norm(i_train-X_pred)\n",
    "    return dist\n",
    "\n",
    "def predict(X_pred, k):\n",
    "    dists = []\n",
    "    for i in X_train:\n",
    "        dists.append(get_dist(i, X_pred))\n",
    "    \n",
    "    idx = np.argpartition(dists, k)\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "        \n",
    "    #plot_digit(0, False)\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    return result\n",
    "\n",
    "def KNN(X_data, y_data):\n",
    "    k = 8\n",
    "    num_errors = 0\n",
    "    for i in range(len(X_data)):\n",
    "        pred = predict(X_data[i], k)\n",
    "        if pred != y_data[i]:\n",
    "            num_errors += 1\n",
    "        if i % 20 == 0 and i != 0:\n",
    "            print(\"Iteration:\", i, \"error:\", (num_errors/i)*100,\"%\")\n",
    "        \n",
    "    error = num_errors/len(X_test)\n",
    "    print('For k={k_value} the error is: {error}%'.format(k_value=k, error=error*100))\n",
    "            \n",
    "KNN(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 20 error: 10.0 %\n",
      "For k=8 the error is: 0.40040040040040037%\n",
      "[[   0    1    2 ... 2996 2997 2998]\n",
      " [   0    1    2 ... 2996 2997 2998]\n",
      " [   0    1    2 ... 2996 2997 2998]\n",
      " ...\n",
      " [   0    1    2 ... 2996 2997 2998]\n",
      " [   0    1    2 ... 2996 2997 2998]\n",
      " [   0    1    2 ... 2996 2997 2998]]\n"
     ]
    }
   ],
   "source": [
    "def get_dist_vector(X_pred, k):\n",
    "    dists = []\n",
    "    for i in X_train:\n",
    "        dists.append(get_dist(i, X_pred))\n",
    "        \n",
    "    idx = np.argpartition(dists, k)\n",
    "    votes = []\n",
    "    for i in range(k):\n",
    "        votes.append(y_train[idx[i]])\n",
    "        \n",
    "    #plot_digit(0, False)\n",
    "    votes = np.asarray(votes)\n",
    "    counts = np.bincount(votes)\n",
    "    result = np.argmax(counts)\n",
    "    dists = np.asarray(dists)\n",
    "    return result, dists\n",
    "\n",
    "def KNN(X_data, y_data):\n",
    "    k = 8\n",
    "    num_errors = 0\n",
    "    \n",
    "    distance_mat = []\n",
    "    \n",
    "    #for i in range(len(X_data)):\n",
    "    for i in range(40):\n",
    "\n",
    "        pred, dist = get_dist_vector(X_data[i], k)\n",
    "        distance_mat.append(dist)\n",
    "        if pred != y_data[i]:\n",
    "            num_errors += 1\n",
    "        if i % 20 == 0 and i != 0:\n",
    "            print(\"Iteration:\", i, \"error:\", (num_errors/i)*100,\"%\")\n",
    "        \n",
    "    error = num_errors/len(X_test)\n",
    "    print('For k={k_value} the error is: {error}%'.format(k_value=k, error=error*100))\n",
    "    \n",
    "    distance_mat = np.asarray(distance_mat)\n",
    "    #distance_mat.sort(axis=1)\n",
    "    indx = distance_mat.argsort(axis=1)\n",
    "    print(indx)\n",
    "    #print(distance_mat[0])\n",
    "    return distance_mat\n",
    "\n",
    "            \n",
    "distance_matrix = KNN(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a) Write down your implementation of k-NN neighbors (using as training data\n",
    "MNIST train small.csv) and report on its accuracy to predict the labels\n",
    "in both the training and test sets (respectively MNIST train small.csv and\n",
    "MNIST test small.csv). For this question use the simple Euclidean distance. Make\n",
    "a table of results for k 2 f1; : : : ; 20g, plot your the empirical training and test loss\n",
    "as a function of k, and comment on your results. Explain how ties are broken in\n",
    "Equation 1.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "b) Obviously the choice of the number of neighbors k is crucial to obtain good performance.\n",
    "This choice must be made WITHOUT LOOKING at the test dataset.\n",
    "Although one can use rules-of-thumb, a possibility is to use cross-validation. Leave-\n",
    "One-Out Cross-Validation (LOOCV) is extremely simple in our context. Implement\n",
    "LOOCV to estimate the risk of the k-NN rule for k 2 f1; : : : ; 20g. Report these\n",
    "LOOCV risk estimates4 on a table and plot them as well the empirical loss on the test\n",
    "dataset (that you obtained in (a)). Given your results, what would be a good choice\n",
    "for k? Comment on your results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "c) Obviously, the choice of distance metric also plays an important role. Consider a\n",
    "simple generalization of the Euclidean distance, namely `p distances (also known as\n",
    "Minkowski distances). For x; y 2 Rl de\f",
    "ne\n",
    "dp(x; y) =\n",
    " \n",
    "Xl\n",
    "i=1\n",
    "jxi ô€€€ yijp\n",
    "!1=p\n",
    ";\n",
    "where p \u0015 1. Use leave-one-out cross validation to simultaneously choose a good value\n",
    "for k 2 f1; : : : ; 20g and p 2 [1; 15].\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "d) (this question is more open) Building up on your work for the previous questions\n",
    "suggest a di\u000b",
    "erent distance metric or some pre-processing of the data that you consider\n",
    "appropriate to improve the performance of the k-NN method. Note that, any choices\n",
    "you make should be done solely based on the training data (that is, do not clairvoyantly\n",
    "optimize the performance of your method on the test data). Clearly justify ALL the\n",
    "choices made and describe the exact steps you took. Someone reading your report\n",
    "should be able to replicate your results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now that you implemented and tested your methodologies in a smaller scale, let us see\n",
    "how these methods scale to the full datasets. For the remaining questions you will use the\n",
    "full MNIST training and test sets.\n",
    "\n",
    "e) Make use of either the Euclidean distance or dp with your choice of p in part (c)\n",
    "(use only one or the other). Determine a good value for k using leave-one-out cross\n",
    "validation when considering the full training set (60000 examples). Was your implementation\n",
    "able to cope with this large amount of data? Did you have to modify it\n",
    "in any way? If so, explain what you did. What is the risk estimate you obtain via\n",
    "cross-validation?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "f) (it is only possible to answer this question after I provide you the \f",
    "le\n",
    "MNIST test.csv) Using the choice of k in part (e) compute the loss of your method\n",
    "on the test set provided. How does this compare with the cross-validation estimate\n",
    "you computed in (e)? Would you choose a di\u000b",
    "erent value for k had you been allowed\n",
    "to look at the test dataset earlier?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "g) Bonus question: each training example is currently a high-dimensional vector. A\n",
    "very successful idea in machine learning is that of dimensionality reduction. This is\n",
    "typically done in an unsupervised way - feature vectors are transformed so that most\n",
    "information is preserved, while signi\f",
    "cantly lowering their dimension. A possibility in\n",
    "our setting is to use Principal Component Analysis (PCA) to map each digit image\n",
    "to a lower dimensional vector. There is an enormous computational advantage (as\n",
    "computing distances will be easier) but there might be also an advantage in terms\n",
    "of statistical generalization. Use this idea in our setting, and choose a good number\n",
    "of principal components to keep in order to have good accuracy (again, this choice\n",
    "should be solely based on the training data). Document clearly all the steps of your\n",
    "procedure. In this question you are allowed to use an existing implementation of PCA\n",
    "or related methods.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
